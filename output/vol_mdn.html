
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="robots" content="" />

  <link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:ital,wght@0,400;0,700;1,400&family=Source+Sans+Pro:ital,wght@0,300;0,400;0,700;1,400&display=swap" rel="stylesheet">

    <link rel="stylesheet" type="text/css" href="https://eadains.github.io/OptionallyBayes/theme/stylesheet/style.min.css">


    <link id="pygments-light-theme" rel="stylesheet" type="text/css"
          href="https://eadains.github.io/OptionallyBayes/theme/pygments/github.min.css">


  <link rel="stylesheet" type="text/css" href="https://eadains.github.io/OptionallyBayes/theme/font-awesome/css/fontawesome.css">
  <link rel="stylesheet" type="text/css" href="https://eadains.github.io/OptionallyBayes/theme/font-awesome/css/brands.css">
  <link rel="stylesheet" type="text/css" href="https://eadains.github.io/OptionallyBayes/theme/font-awesome/css/solid.css">





  


<meta name="author" content="Erik Dains" />
<meta name="description" content="Using a mixture density neural network implemented in PyTorch to forecast the distribution of future realized volatility." />
<meta name="keywords" content="volatility, forecasting, mixture-density-network, machine-learning, pytorch, model-building">


<meta property="og:site_name" content="Optionally Bayes"/>
<meta property="og:title" content="Mixture Density Network for Forecasting Realized Volatility"/>
<meta property="og:description" content="Using a mixture density neural network implemented in PyTorch to forecast the distribution of future realized volatility."/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="https://eadains.github.io/OptionallyBayes/vol_mdn.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2021-04-07 00:00:00-05:00"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="https://eadains.github.io/OptionallyBayes/author/erik-dains.html">
<meta property="article:section" content="Volatility"/>
<meta property="article:tag" content="volatility"/>
<meta property="article:tag" content="forecasting"/>
<meta property="article:tag" content="mixture-density-network"/>
<meta property="article:tag" content="machine-learning"/>
<meta property="article:tag" content="pytorch"/>
<meta property="article:tag" content="model-building"/>
<meta property="og:image" content="https://eadains.github.io/OptionallyBayes/photos/headshot.jpg">

  <title>Optionally Bayes &ndash; Mixture Density Network for Forecasting Realized Volatility</title>

</head>
<body class="light-theme">
  <aside>
    <div>
      <a href="https://eadains.github.io/OptionallyBayes">
        <img src="https://eadains.github.io/OptionallyBayes/photos/headshot.jpg" alt="Optionally Bayes" title="Optionally Bayes">
      </a>

      <h1>
        <a href="https://eadains.github.io/OptionallyBayes">Optionally Bayes</a>
      </h1>

<p>My journey in life and math. Anything goes.</p>


      <ul class="social">
          <li>
            <a  class="sc-github" href="https://github.com/eadains" target="_blank">
              <i class="fab fa-github"></i>
            </a>
          </li>
          <li>
            <a  class="sc-instagram" href="https://www.instagram.com/erikdains/" target="_blank">
              <i class="fab fa-instagram"></i>
            </a>
          </li>
          <li>
            <a  class="sc-linkedin" href="https://www.linkedin.com/in/erik-dains/" target="_blank">
              <i class="fab fa-linkedin"></i>
            </a>
          </li>
      </ul>
    </div>

  </aside>
  <main>

    <nav>
      <a href="https://eadains.github.io/OptionallyBayes">Home</a>

      <a href="archives.html">Archives</a>
      <a href="categories.html">Categories</a>
      <a href="tags.html">Tags</a>


    </nav>

<article class="single">
  <header>
      
    <h1 id="vol_mdn">Mixture Density Network for Forecasting Realized Volatility</h1>
    <p>
      Posted on Wed 07 April 2021 in <a href="https://eadains.github.io/OptionallyBayes/category/volatility.html">Volatility</a>

    </p>
  </header>


  <div>
    <hr>
<p>Okay, today we are moving up in the world and I'm going to use the magic of neural networks to forecast volatility.</p>
<h1>The Data</h1>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">sqlite3</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>

<span class="c1"># Set default figure size</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;figure.figsize&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">plotting</span><span class="o">.</span><span class="n">register_matplotlib_converters</span><span class="p">()</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="c1"># Here&quot;s my minute data for the S&amp;P 500</span>
<span class="n">spx_minute</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;SPX_1min.csv&quot;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;datetime&quot;</span><span class="p">,</span> <span class="s2">&quot;open&quot;</span><span class="p">,</span> <span class="s2">&quot;high&quot;</span><span class="p">,</span> <span class="s2">&quot;low&quot;</span><span class="p">,</span> <span class="s2">&quot;close&quot;</span><span class="p">],</span>
                                  <span class="n">index_col</span><span class="o">=</span><span class="s2">&quot;datetime&quot;</span><span class="p">,</span> <span class="n">parse_dates</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="c1"># Here&quot;s the function for calculating the 1-min RV, as discussed in my last post</span>
<span class="k">def</span> <span class="nf">rv_calc</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">date</span><span class="p">):</span>
        <span class="n">returns</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;close&quot;</span><span class="p">])</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;close&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">results</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">returns</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">spx_variance</span> <span class="o">=</span> <span class="n">rv_calc</span><span class="p">(</span><span class="n">spx_minute</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">conn</span> <span class="o">=</span> <span class="n">sqlite3</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="s2">&quot;data.db&quot;</span><span class="p">)</span>
<span class="n">spx_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_sql</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM prices WHERE ticker=&#39;^GSPC&#39;&quot;</span><span class="p">,</span> <span class="n">conn</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s2">&quot;date&quot;</span><span class="p">,</span> <span class="n">parse_dates</span><span class="o">=</span><span class="s2">&quot;date&quot;</span><span class="p">)</span>
<span class="n">spx_returns</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">spx_data</span><span class="p">[</span><span class="s2">&quot;close&quot;</span><span class="p">])</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">spx_data</span><span class="p">[</span><span class="s2">&quot;close&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">spx_returns</span> <span class="o">=</span> <span class="n">spx_returns</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>

<span class="n">vix_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_sql</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM prices WHERE ticker=&#39;^VIX&#39;&quot;</span><span class="p">,</span> <span class="n">conn</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s2">&quot;date&quot;</span><span class="p">,</span> <span class="n">parse_dates</span><span class="o">=</span><span class="s2">&quot;date&quot;</span><span class="p">)</span>
<span class="c1"># This puts it into units of daily standard deviation</span>
<span class="n">vix</span> <span class="o">=</span> <span class="n">vix_data</span><span class="p">[</span><span class="s2">&quot;close&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">252</span><span class="p">)</span> <span class="o">/</span> <span class="mi">100</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">create_lags</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">lags</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates a dataframe with lagged values of the given series.</span>
<span class="sd">    Generates columns named x_t-n which means the value of each row is the value of the original series lagged n times</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">series</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
    <span class="n">result</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_t&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">series</span>

    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">lags</span><span class="p">):</span>
        <span class="n">result</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_t-</span><span class="si">{</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">series</span><span class="o">.</span><span class="n">shift</span><span class="p">((</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">result</span>
</code></pre></div>

<p>The predictive variables are the VIX, returns of the index, and our calculated realized variance. I include the 21 past values of these variables.</p>
<div class="highlight"><pre><span></span><code><span class="n">vix_lags</span> <span class="o">=</span> <span class="n">create_lags</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">vix</span><span class="p">),</span> <span class="mi">21</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;vix&quot;</span><span class="p">)</span>
<span class="n">return_lags</span> <span class="o">=</span> <span class="n">create_lags</span><span class="p">(</span><span class="n">spx_returns</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;returns&quot;</span><span class="p">)</span>
<span class="n">rv_lags</span> <span class="o">=</span> <span class="n">create_lags</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">spx_variance</span><span class="p">),</span> <span class="mi">21</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;rv&quot;</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">vix_lags</span><span class="p">,</span> <span class="n">return_lags</span><span class="p">,</span> <span class="n">rv_lags</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
<span class="c1"># We want to predict log of variance</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">spx_variance</span><span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">))</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>

<span class="n">common_index</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">common_index</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">common_index</span><span class="p">]</span>
</code></pre></div>

<h1>The Model</h1>
<p>I'm using a mixture density network to model future volatility. This is because I want an estimate of the future <em>distribution</em> of volatility, not just a point estimate. A mixture density network outputs the parameters for making a mixture of normal distributions. This is useful because you can approximate any arbitrary distribution with a large enough mixture of only normal distributions.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">torch.distributions</span> <span class="kn">import</span> <span class="n">Categorical</span><span class="p">,</span> <span class="n">Normal</span><span class="p">,</span> <span class="n">Independent</span><span class="p">,</span> <span class="n">MixtureSameFamily</span>
<span class="kn">from</span> <span class="nn">torch.optim.swa_utils</span> <span class="kn">import</span> <span class="n">AveragedModel</span><span class="p">,</span> <span class="n">SWALR</span>

<span class="n">torch</span><span class="o">.</span><span class="n">set_default_dtype</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">MDN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">n_components</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">=</span> <span class="n">n_components</span>
        <span class="c1"># Last layer output dimension rationale:</span>
        <span class="c1"># Need two parameters for each distributionm thus 2 * n_components.</span>
        <span class="c1"># Need each of those for each output dimension, thus that multiplication</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm_network</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">n_components</span> <span class="o">*</span> <span class="n">out_dim</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cat_network</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">n_components</span> <span class="o">*</span> <span class="n">out_dim</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">norm_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_network</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># Split so we get parameters for mean and standard deviation</span>
        <span class="n">mean</span><span class="p">,</span> <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">norm_params</span><span class="p">,</span> <span class="n">norm_params</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># We need rightmost dimension to be n_components for mixture</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">mean</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">mean</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">)</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">std</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">std</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">)</span>
        <span class="n">normal</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">std</span><span class="p">))</span>

        <span class="n">cat_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cat_network</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># Again, rightmost dimension must be n_components</span>
        <span class="n">cat</span> <span class="o">=</span> <span class="n">Categorical</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">cat_params</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">cat_params</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">MixtureSameFamily</span><span class="p">(</span><span class="n">cat</span><span class="p">,</span> <span class="n">normal</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">test_index</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="o">.</span><span class="mi">75</span><span class="p">)</span>
<span class="n">train_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">test_index</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">train_y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">test_index</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">test_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">:]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">test_y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">:]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

<span class="n">in_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">out_dim</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">n_components</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">250</span>
</code></pre></div>

<p>Below here is the training loop. I'm using a cosine annealing learning rate schedule to better explore the parameter space, as well as using model averaging over the last 500 iterations so the model generalizes better.</p>
<div class="highlight"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">MDN</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">n_components</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=.</span><span class="mi">001</span><span class="p">)</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">CosineAnnealingWarmRestarts</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">swa_model</span> <span class="o">=</span> <span class="n">AveragedModel</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">swa_start</span> <span class="o">=</span> <span class="mi">400</span>
<span class="n">swa_scheduler</span> <span class="o">=</span> <span class="n">SWALR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">swa_lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">anneal_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">anneal_strategy</span><span class="o">=</span><span class="s2">&quot;cos&quot;</span><span class="p">)</span>

<span class="n">train_losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">validation_losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="n">swa_model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">500</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">train_x</span><span class="p">)</span>

    <span class="n">train_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">output</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">train_y</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>

    <span class="n">test_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">model</span><span class="p">(</span><span class="n">test_x</span><span class="p">)</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">test_y</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">validation_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_loss</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>

    <span class="n">train_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="n">swa_start</span><span class="p">:</span>
        <span class="n">swa_model</span><span class="o">.</span><span class="n">update_parameters</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="n">swa_scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_losses</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">validation_losses</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Training Epochs&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Model Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Training &amp; Validation Losses&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Training&quot;</span><span class="p">,</span> <span class="s2">&quot;Validation&quot;</span><span class="p">])</span>
</code></pre></div>

<p><img alt="png" src="https://eadains.github.io/OptionallyBayes/photos/04_07_2021/output_17_1.png"></p>
<div class="highlight"><pre><span></span><code><span class="n">swa_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">output_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">swa_model</span><span class="p">(</span><span class="n">test_x</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()))</span>
<span class="n">y_trans</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">test_y</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()))</span>

<span class="n">output_sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">swa_model</span><span class="p">(</span><span class="n">test_x</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">([</span><span class="mi">5000</span><span class="p">])</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()))</span>
</code></pre></div>

<p>Our out-of-sample R-squared is excellent, much higher than my previous simple linear model.</p>
<div class="highlight"><pre><span></span><code><span class="n">regress</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">linregress</span><span class="p">(</span><span class="n">output_mean</span><span class="p">,</span> <span class="n">y_trans</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;R-squared: </span><span class="si">{</span><span class="n">regress</span><span class="o">.</span><span class="n">rvalue</span><span class="o">**</span><span class="mi">2</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>    R-squared: 0.7128714654332561
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">output_mean</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y_trans</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Time&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Volatility&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Predicted and Actual Volatility&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Model&quot;</span><span class="p">,</span> <span class="s2">&quot;Actual&quot;</span><span class="p">])</span>
</code></pre></div>

<p><img alt="png" src="https://eadains.github.io/OptionallyBayes/photos/04_07_2021/output_21_1.png"></p>
<p>Our distributional assumption also does well. We expect 5% of cases to be outside what the model distribution forecasts, and we find that to be the case.</p>
<div class="highlight"><pre><span></span><code><span class="n">percent</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">output_sample</span><span class="p">,</span> <span class="mi">95</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of exceedences: </span><span class="si">{</span><span class="p">(</span><span class="n">y_trans</span> <span class="o">&gt;</span> <span class="n">percent</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_trans</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>    Number of exceedences: 0.04477611940298507
</code></pre></div>

<p>Further testing the distribution accuracy, let's see if doing a probability integral transform yields a uniform.</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">ECDF</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sorted</span> <span class="o">=</span> <span class="n">data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sorted</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sorted</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sorted</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sorted</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_trans</span><span class="p">)):</span>
    <span class="n">ecdf</span> <span class="o">=</span> <span class="n">ECDF</span><span class="p">(</span><span class="n">output_sample</span><span class="p">[</span><span class="n">x</span><span class="p">])</span>
    <span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ecdf</span><span class="p">(</span><span class="n">y_trans</span><span class="p">[</span><span class="n">x</span><span class="p">]))</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div>

<p><img alt="png" src="https://eadains.github.io/OptionallyBayes/photos/04_07_2021/output_27_1.png"></p>
<div class="highlight"><pre><span></span><code><span class="n">stats</span><span class="o">.</span><span class="n">kstest</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="s2">&quot;uniform&quot;</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>    KstestResult(statistic=0.028702640642939155, pvalue=0.46125545362008036)
</code></pre></div>

<p>We can't reject the null hypothesis that the transformed values come from a uniform distribution! That means our distributions accurately models the data's real distribution.</p>
<h1>Conclusion</h1>
<p>This model seems quite excellent. I'm going to use this model for my future posts about how to make an effective trading strategy. Next time I'm going to discuss Kelly Bet Sizing and its application to continuous distributions.</p>
  </div>
  <div class="tag-cloud">
    <p>
      <a href="https://eadains.github.io/OptionallyBayes/tag/volatility.html">volatility</a>
      <a href="https://eadains.github.io/OptionallyBayes/tag/forecasting.html">forecasting</a>
      <a href="https://eadains.github.io/OptionallyBayes/tag/mixture-density-network.html">mixture-density-network</a>
      <a href="https://eadains.github.io/OptionallyBayes/tag/machine-learning.html">machine-learning</a>
      <a href="https://eadains.github.io/OptionallyBayes/tag/pytorch.html">pytorch</a>
      <a href="https://eadains.github.io/OptionallyBayes/tag/model-building.html">model-building</a>
    </p>
  </div>





</article>

    <footer>
<p>&copy; 2020 Erik Dains</p>
<p>
Built with <a href="http://getpelican.com" target="_blank">Pelican</a> using <a href="http://bit.ly/flex-pelican" target="_blank">Flex</a> theme
</p>    </footer>
  </main>




<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " Optionally Bayes ",
  "url" : "https://eadains.github.io/OptionallyBayes",
  "image": "https://eadains.github.io/OptionallyBayes/photos/headshot.jpg",
  "description": ""
}
</script>

</body>
</html>